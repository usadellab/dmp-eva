# Example Data Management Plan - Research Project

**Project Title:** Impact of Climate Change on Alpine Biodiversity
**Project Phase:** Proposal/Early Stage
**Principal Investigator:** Dr. Jane Smith
**Institution:** University Research Center
**Duration:** 36 months
**Funding Agency:** European Research Council

## 1. Data Description and Collection

### 1a. Data Collection or Re-use
We will collect new observational data on alpine plant species diversity through field surveys across 50 sites in the European Alps. Data collection will employ standardized ecological survey methods using GPS-enabled tablets and digital photography equipment. We will also reuse historical biodiversity data from the Global Biodiversity Information Facility (GBIF) database to establish baseline comparisons spanning the past 50 years.

### 1b. Data Types, Formats, and Volumes
- **Field observations:** CSV format, approximately 10,000 records per year (est. 5MB annually)
- **Photographs:** JPEG format, ~5000 images per year (est. 20GB annually)
- **Environmental measurements:** NetCDF format for temperature, precipitation, and soil data (est. 2GB annually)
- **GIS data:** Shapefiles and GeoTIFF for spatial analysis (est. 500MB)
- **Historical reuse data:** Downloaded from GBIF in Darwin Core format

## 2. Documentation and Data Quality

### 2a. Metadata and Documentation Standards
We will implement the Ecological Metadata Language (EML) standard for all biodiversity observations. Field data will be documented using controlled vocabularies from the Darwin Core standard. All metadata will include:
- Descriptive metadata: Project title, principal investigators, funding information, temporal and spatial coverage
- Process metadata: Survey protocols, equipment specifications (Garmin GPS units, Canon EOS cameras), sampling methods
- Tools: We will use QGIS for spatial data management and custom Python scripts for data processing

Metadata will be stored in XML format alongside data files and also maintained in a centralized PostgreSQL database.

### 2b. Data Quality Control
Quality control procedures include:
- Double-entry verification for 10% of field observations
- Automated range checks for environmental measurements
- Cross-validation with historical datasets
- Version control using Git for all data processing scripts
- Regular backups and integrity checksums (MD5) for all data files
- Peer review of data collection protocols by project steering committee

## 3. Storage and Backup

### 3a. Storage and Backup Procedures
During the project, data will be stored on the university's secure file server with RAID-6 configuration. Daily incremental backups will be performed automatically to a separate backup server, with weekly full backups retained for one year. Field data will be uploaded to the server within 48 hours of collection.

The university IT department provides storage infrastructure with 99.9% uptime guarantee. Total storage allocation: 500GB with expansion capability to 2TB if needed.

### 3b. Data Access Management
Access will be granted to:
- Principal Investigator and Co-Investigators (full read/write access)
- 3 PhD students conducting fieldwork (read/write access to field data)
- 2 data stewards (read-only access for quality control)
- External collaborators from partner institutions (restricted access via secure FTP)

Access will be managed through the university's Active Directory system with multi-factor authentication. Access logs will be maintained and reviewed quarterly.

### 3c. Data Security and Protection
The project does not involve personal data, sensitive species locations, or confidential information. However, we will implement standard security measures:
- Encrypted file transfer (SFTP) for data exchange with collaborators
- Restricted physical access to server rooms (university IT security protocols)
- Regular security updates and patches applied by IT department
- Firewall protection and intrusion detection systems

## 4. Legal and Ethical Requirements

### 4a. Personal Data and GDPR Compliance
This project does not process personal data as defined by GDPR. All data collected relates to plant species and environmental conditions only.

### 4b. Intellectual Property Rights
All data generated by this project will be owned by the university in accordance with institutional IP policy. Collaborating institutions will retain rights to data they contribute, with clear data sharing agreements established at project start. Any publications will follow standard academic authorship guidelines. We do not anticipate patent applications or commercial exploitation.

### 4c. Ethical Requirements
The project has received ethics clearance from the university Research Ethics Committee (Approval #2024-BIO-089). Fieldwork will comply with national regulations for accessing protected areas, with permits obtained from relevant authorities in each country. No animal research or human subjects are involved.

## 5. Data Sharing and Preservation

### 5a. Data Sharing Plans
We will make all observational data publicly available within 12 months of project completion through:
- GBIF (for biodiversity observations)
- PANGAEA (for environmental data)
- Institutional repository (University Digital Archive)

Data will be released under Creative Commons Attribution 4.0 International (CC BY 4.0) license. A 12-month embargo will apply to allow primary researchers to publish results. Photographs may have longer embargo (24 months) to allow for atlas publication.

### 5b. Long-term Preservation
Data will be preserved for at least 10 years in:
- GBIF (biodiversity observations) - indefinite preservation
- PANGAEA (environmental data) - minimum 10 years
- University Digital Archive - institutional policy requires 10-year retention

Selection criteria for long-term preservation:
- All finalized, quality-controlled datasets
- Complete metadata and documentation
- Representative raw data samples (10% of photographs)

### 5c. Access Methods and Tools
Data formats for preservation:
- Tabular data: CSV (open format)
- Photographs: JPEG (widely supported)
- Spatial data: GeoTIFF and Shapefile (standard GIS formats)
- Environmental data: NetCDF (CF conventions)

Required software:
- R or Python for statistical analysis (open-source)
- QGIS for spatial data visualization (open-source)
- Standard spreadsheet software for CSV files

All analysis scripts will be published on GitHub with open-source licenses (MIT License). A Jupyter notebook will be provided to demonstrate key analyses.

### 5d. Persistent Identifiers
Each deposited dataset will receive a Digital Object Identifier (DOI) from the respective repository:
- GBIF datasets: GBIF DOI system
- PANGAEA datasets: PANGAEA DOI service
- Institutional repository: University DOI service

DOIs will be included in all publications citing the data.

## 6. Data Management Responsibilities and Resources

### 6a. Roles and Responsibilities
- **Principal Investigator (Dr. Jane Smith):** Overall data management strategy, compliance with funder requirements, data publication decisions
- **Project Data Manager (John Doe):** Day-to-day data management, quality control, metadata creation, repository submissions
- **PhD Students (3):** Data collection, initial data entry, basic quality checks
- **University Data Steward (Sarah Johnson):** Advisory support, DMP reviews, repository guidance
- **IT Department:** Storage infrastructure, backup systems, security

Post-project data maintenance will be handled by the university Research Data Management Service.

### 6b. Resources for FAIR Data
**Human resources:**
- Data Manager: 0.5 FTE throughout project duration (€60,000)
- Data Steward consultation: 20 hours per year (institutional service)
- PhD student data management training: 40 hours total (€2,000)

**Infrastructure:**
- Server storage: Provided by university (no additional cost)
- Backup systems: Institutional service (no additional cost)
- Repository deposits: Free for GBIF and PANGAEA
- DOI minting: Institutional service (no additional cost)

**Software/Tools:**
- Open-source tools: R, Python, QGIS (no cost)
- Commercial software licenses: Provided by university (no additional cost)

**Training:**
- RDM workshop attendance: €1,000
- Metadata standards workshop: €800

**Total estimated RDM costs:** €63,800 over 36 months (~7% of project budget)

---

**DMP Version:** 1.0
**Last Updated:** January 2025
**Contact:** jane.smith@university.edu
